# -*- coding: utf-8 -*-
"""Embeddingé…ç½® - æœ¬åœ°embeddingæ¨¡å‹å®ç°"""

import os
import asyncio
from datetime import datetime
from pathlib import Path
from agentscope.embedding import EmbeddingModelBase, EmbeddingResponse, EmbeddingUsage
from agentscope.message import TextBlock
import hashlib
import math
import random

class SmartLocalEmbedding(EmbeddingModelBase):
    """æ™ºèƒ½æœ¬åœ°embeddingç³»ç»Ÿï¼Œä¼˜å…ˆä½¿ç”¨é¢„ä¸‹è½½æ¨¡å‹ï¼Œæ— éœ€ç½‘ç»œ"""
    
    supported_modalities = ["text"]
    
    def __init__(self, model_name: str = "local-smart", dimensions: int = 1536) -> None:
        super().__init__(model_name, dimensions)
        self.model = None
        self.model_path = "A2S/models/embedding_model"  # æŒ‡å‘æ–°çš„embeddingæ¨¡å‹è·¯å¾„
        self.model_status = "unknown"
        self._initialize_model()
    
    def _initialize_model(self):
        """æ™ºèƒ½åˆå§‹åŒ–æ¨¡å‹"""
        print("ğŸ” æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½æœ¬åœ°embeddingç³»ç»Ÿ...")
        
        # æ£€æŸ¥æœ¬åœ°æ¨¡å‹
        if self._check_local_model():
            self.model_status = "local_model"
            print("âœ… æ£€æµ‹åˆ°æœ¬åœ°é¢„ä¸‹è½½æ¨¡å‹ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
        else:
            self.model_status = "mathematical"
            print("âš ï¸  æœªæ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹ï¼Œå°†ä½¿ç”¨æ•°å­¦æ–¹æ³•ç”Ÿæˆembedding")
    
    def _check_local_model(self):
        """æ£€æŸ¥æœ¬åœ°é¢„ä¸‹è½½æ¨¡å‹"""
        try:
            from sentence_transformers import SentenceTransformer
            
            model_path = Path(self.model_path)
            print(f"ğŸ” æ£€æŸ¥embeddingæ¨¡å‹è·¯å¾„: {model_path.absolute()}")
            
            # æ£€æŸ¥embeddingæ¨¡å‹æ–‡ä»¶
            model_files = [
                "config.json",
                "model.safetensors", 
                "pytorch_model.bin",
                "modules.json",
                "tokenizer.json"  # æ·»åŠ tokenizeræ£€æŸ¥
            ]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ¨¡å‹æ–‡ä»¶
            has_model = any((model_path / file).exists() for file in model_files)
            
            if has_model:
                print(f"ğŸ”„ æ­£åœ¨åŠ è½½æœ¬åœ°embeddingæ¨¡å‹: {self.model_path}")
                self.model = SentenceTransformer(str(model_path))
                print(f"âœ… æˆåŠŸåŠ è½½æœ¬åœ°embeddingæ¨¡å‹: {self.model_path}")
                return True
            else:
                print(f"ğŸ“­ æœªæ‰¾åˆ°æœ¬åœ°embeddingæ¨¡å‹æ–‡ä»¶")
                if model_path.exists():
                    files = [f.name for f in model_path.iterdir() if f.is_file()]
                    print(f"ğŸ“‚ embeddingç›®å½•å†…å®¹: {files}")
                return False
        except ImportError:
            print("âš ï¸  æœªå®‰è£…sentence-transformersï¼Œå°†ä½¿ç”¨çº¯æ•°å­¦æ–¹æ³•")
            return False
        except Exception as e:
            print(f"âš ï¸  åŠ è½½æœ¬åœ°embeddingæ¨¡å‹å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨æ•°å­¦æ–¹æ³•")
            return False
    
    async def __call__(self, text: list[str | TextBlock], **kwargs: any) -> EmbeddingResponse:
        gather_text = []
        for item in text:
            if isinstance(item, dict) and "text" in item:
                gather_text.append(item["text"])
            elif isinstance(item, str):
                gather_text.append(item)
            else:
                raise ValueError("Input text must be a list of strings or TextBlock dicts.")
        
        # å¦‚æœæœ‰æœ¬åœ°æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨
        if self.model is not None:
            try:
                start_time = datetime.now()
                # åœ¨å¼‚æ­¥å‡½æ•°ä¸­è¿è¡ŒåŒæ­¥æ¨¡å‹
                embeddings = await asyncio.get_event_loop().run_in_executor(
                    None, self.model.encode, gather_text
                )
                time = (datetime.now() - start_time).total_seconds()
                
                # è°ƒæ•´ç»´åº¦åˆ°1536ï¼ˆå¦‚æœéœ€è¦ï¼‰
                embeddings = self._adjust_dimensions(embeddings.tolist())
                
                return EmbeddingResponse(
                    embeddings=embeddings,
                    usage=EmbeddingUsage(tokens=sum(len(t) for t in gather_text), time=time),
                    source="local_model"
                )
            except Exception as e:
                print(f"âŒ æœ¬åœ°embeddingæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}ï¼Œé™çº§åˆ°æ•°å­¦æ–¹æ³•")
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨æ•°å­¦æ–¹æ³•ç”Ÿæˆå‘é‡
        print("âš ï¸  ä½¿ç”¨æ•°å­¦æ–¹æ³•ç”Ÿæˆembeddingï¼ˆå®Œå…¨ç¦»çº¿ï¼‰")
        embeddings = self._generate_mathematical_embeddings(gather_text)
        
        return EmbeddingResponse(
            embeddings=embeddings,
            usage=EmbeddingUsage(tokens=sum(len(t) for t in gather_text), time=0.01),
            source="mathematical"
        )
    
    def _adjust_dimensions(self, embeddings):
        """è°ƒæ•´å‘é‡ç»´åº¦åˆ°ç›®æ ‡ç»´åº¦"""
        adjusted = []
        for emb in embeddings:
            current_dim = len(emb)
            if current_dim < self.dimensions:
                # æ‰©å±•ç»´åº¦ï¼šä½¿ç”¨æ•°å­¦æ–¹æ³•æ‰©å±•
                extended = self._extend_vector(emb, self.dimensions)
                adjusted.append(extended)
            elif current_dim > self.dimensions:
                # ç¼©å‡ç»´åº¦ï¼šæˆªæ–­å¹¶é‡æ–°å½’ä¸€åŒ–
                truncated = emb[:self.dimensions]
                norm = sum(x*x for x in truncated) ** 0.5
                normalized = [x/norm for x in truncated]
                adjusted.append(normalized)
            else:
                adjusted.append(emb)
        return adjusted
    
    def _extend_vector(self, vector, target_dim):
        """ä½¿ç”¨æ•°å­¦æ–¹æ³•æ‰©å±•å‘é‡"""
        extended = vector.copy()
        current_len = len(extended)
        
        # ä½¿ç”¨ä¸åŒçš„æ•°å­¦å˜æ¢æ‰©å±•
        seed = sum(ord(c) for c in str(extended)) % 1000
        rng = random.Random(seed)
        
        while len(extended) < target_dim:
            # åŸºäºç°æœ‰å‘é‡çš„æ•°å­¦å˜æ¢
            for val in vector:
                if len(extended) >= target_dim:
                    break
                # æ·»åŠ ä¸€äº›å˜åŒ–ä½†ä¿æŒç¡®å®šæ€§
                transformed = math.sin(val * (len(extended) + 1) + seed) * 0.5 + 0.5
                extended.append(transformed)
        
        # å½’ä¸€åŒ–
        norm = sum(x*x for x in extended) ** 0.5
        return [x/norm for x in extended]
    
    def _generate_mathematical_embeddings(self, texts):
        """ä½¿ç”¨æ•°å­¦æ–¹æ³•ç”Ÿæˆembeddingå‘é‡"""
        embeddings = []
        for text in texts:
            # åŸºäºæ–‡æœ¬å†…å®¹çš„ç¡®å®šæ€§å‘é‡ç”Ÿæˆ
            hash_val = hashlib.md5(text.encode()).hexdigest()
            
            # ç”ŸæˆåŸºç¡€å‘é‡
            base_vector = []
            for i in range(0, 32, 2):  # MD5æœ‰32ä¸ªåå…­è¿›åˆ¶å­—ç¬¦
                # å°†æ¯ä¸¤ä¸ªå­—ç¬¦è½¬æ¢ä¸º0-1ä¹‹é—´çš„æµ®ç‚¹æ•°
                val = int(hash_val[i:i+2], 16) / 255.0
                base_vector.append(val)
            
            # æ‰©å±•åˆ°ç›®æ ‡ç»´åº¦
            full_vector = []
            seed = hash(text) % 1000
            rng = random.Random(seed)
            
            while len(full_vector) < self.dimensions:
                # ä½¿ç”¨ä¸åŒçš„æ•°å­¦å˜æ¢æ‰©å±•
                for val in base_vector:
                    if len(full_vector) >= self.dimensions:
                        break
                    # æ·»åŠ ä¸€äº›å˜åŒ–ä½†ä¿æŒç¡®å®šæ€§
                    transformed = math.sin(val * (len(full_vector) + 1) + seed) * 0.5 + 0.5
                    full_vector.append(transformed)
            
            # å½’ä¸€åŒ–
            norm = sum(x*x for x in full_vector) ** 0.5
            normalized = [x/norm for x in full_vector]
            embeddings.append(normalized[:self.dimensions])
        
        return embeddings

def create_embedding_model_simple():
    """åˆ›å»ºç®€åŒ–ç‰ˆembeddingæ¨¡å‹"""
    return SmartLocalEmbedding(
        model_name="local-embedding-simple",
        dimensions=1536
    )
