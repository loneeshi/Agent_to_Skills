# file: task_data/config/run_local_campus.yaml

# ======================================================================================
# Campus Life Bench - Local Model Configuration
# ======================================================================================
#
# This configuration file runs the campus_task using a local Hugging Face model.
#
# ======================================================================================

language_model_dict:
  local_model: # Define a new name for the local model
    module: "src.language_models.instance.huggingface_language_model.HuggingfaceLanguageModel"
    parameters:
      # IMPORTANT: Replace with the actual path to your local model
      model_name_or_path: "/path/to/your/local/model"
      role_dict:
        user: "user"
        agent: "assistant"
      # Optional: you can specify dtype and device_map if needed
      # dtype: "auto"
      # device_map: "auto"

agent_dict:
  language_model_agent:
    module: "src.agents.instance.language_model_agent.LanguageModelAgent"
    parameters:
      language_model: "local_model" # Use the name defined above
      system_prompt: "You are a helpful assistant."
      inference_config_dict:
        max_new_tokens: 1024 # Use max_new_tokens for local models
        temperature: 0.0
        do_sample: false # Use greedy decoding

task_dict:
  campus_life_bench:
    module: "src.tasks.instance.campus_life_bench.task.CampusTask"
    parameters:
      task_name:
        module: "src.typings.TaskName"
        parameters:
          value: "campus_life_bench"
      chat_history_item_factory:
        module: "src.factories.chat_history_item.ChatHistoryItemFactory"
        parameters:
          chat_history_item_dict_path: "./chat_history_items/standard/campus_life_bench.json"
      max_round: 60
      data_dir: ""

callback_dict:
  current_session_saving_callback:
    module: "src.callbacks.instance.current_session_saving_callback.CurrentSessionSavingCallback"
    parameters: {}
  consecutive_abnormal_agent_inference_process_handling_callback:
    module: "src.callbacks.instance.consecutive_abnormal_agent_inference_process_handling_callback.ConsecutiveAbnormalAgentInferenceProcessHandlingCallback"
    parameters:
      tolerance_count: 8

assignment_config:
  language_model_list:
  - name: local_model # Use the same name here
    # No custom parameters needed here as they are defined above
  agent:
    name: language_model_agent
    custom_parameters:
      language_model: local_model # Link agent to the local model
  task: campus_life_bench
  callback_dict:
    callback_0:
      name: current_session_saving_callback
    callback_1:
      name: consecutive_abnormal_agent_inference_process_handling_callback
  output_dir: 
  sample_order: default

environment_config:
  use_task_client_flag: false

logger_config:
  log_file_path: default
  level: INFO
  logger_name: lifelong_agent_bench